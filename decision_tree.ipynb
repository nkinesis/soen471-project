{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "df545e50",
   "metadata": {},
   "source": [
    "### Decision Tree Classification Model\n",
    "\n",
    "A decision tree model is a machine learning algorithm that can be used for classification tasks.\n",
    "<br>This classification model is easy to interpret and can handle both categorical and numerical features, thus explaining our choice for this algorithm. \n",
    "<br>The model represents a series of decisions that lead to a final classification decision as a tree-like graph with several nodes. \n",
    "<br>At each node of the tree, a decision is made based on a specific attribute, and each branch represents a different decision or outcome. \n",
    "<br>\n",
    "<br>In classification, the goal is to predict a categorical variable based on a set of input features.\n",
    "<br>For our case - predicting the cost of damage for a fire incident - the set of input features is as follows:\n",
    "<li><b>DateOfCall</b>: the month of the date when the fire incident was reported \n",
    "<li><b>PropertyType</b>: the type of location where the fire incident occured\n",
    "<li><b>NumPumpsAttending</b>: the number of total fire pumps that were deployed to the fire incident location\n",
    "<li><b>PumpHoursRoundUp</b>: the number of hours the fire pumps were used during the fire incident\n",
    "<li><b>mean_temp</b>: mean daily temperature in Celsius (Cº)\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "#### Scikit-Learn Library\n",
    "\n",
    "Our prediction model using the decision tree classifier is implemented with <b><i>scikit-learn</i></b> machine learning library in Python.<br>\n",
    "Please follow the <b>scikit-learn</b>'s installation guide ([https://scikit-learn.org/stable/install.html](Hidden_landing_URL)) and have the library ready before running the code.<br>\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5e49967b",
   "metadata": {},
   "source": [
    "#### 1. Importing Libraries\n",
    "\n",
    "Following libraries and function are necessary to implement the decision tree prediction model.\n",
    "<br>\n",
    "<br>\n",
    "<b> Pandas</b>: \n",
    "<li> Used for data cleaning in preparation for the model training\n",
    "<br><br>\n",
    "<b> tree </b> from sklearn:\n",
    "<li> Scikit-learn's decision tree classifier model library\n",
    "<br><br>\n",
    "<b> train_test_split </b> from sklearn.model_selection:\n",
    "<li> Dividing the data into training and testing sets for model training and peformance analysis\n",
    "<br><br>\n",
    "<b> classification_report</b> from sklearn.metrics:\n",
    "<li> Visualizing and measure the performance of the prediction model\n",
    "<br><br>\n",
    "<b> GridSearchCV</b> from sklearn.model_selection:\n",
    "<li> Hyper parameter tuning\n",
    "<br><br>\n",
    "<b> export_graphviz</b> from sklearn.tree:\n",
    "<li> Vizualize the decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c07b9daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all necessary libraries for decision tree model training and testing\n",
    "\n",
    "#basic libraries for the model building\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#library for measuring the performance metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#library for hyper parameter tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#library for vizualization \n",
    "from sklearn.tree import export_graphviz"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3d4e1fb7",
   "metadata": {},
   "source": [
    "#### 2. Load Dataset\n",
    "\n",
    "Loading the fire incident and weather dataset into <i>oandas</i> dataframe from CSV file.<br>\n",
    "The features present in the cleaned dataset are listed below, alongside the type of data each of them holds.\n",
    "<br>Only selected features will be used for the prediction model.\n",
    "<br>Please refer to below for each data types' equivalent in Python.\n",
    "<br><br>\n",
    "Pandas' datatypes and their Python equivalents:\n",
    "<li> int64 = int\n",
    "<li> float64 = float\n",
    "<li> object = string\n",
    "<br><br>*Please refer to the <b><i>preprocessing</i></b> folder for detailed implementation on data cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60aa0437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DateOfCall             int64\n",
       "CalYear                int64\n",
       "HourOfCall             int64\n",
       "IncidentGroup          int64\n",
       "PropertyCategory       int64\n",
       "PropertyType           int64\n",
       "NumPumpsAttending      int64\n",
       "PumpHoursRoundUp       int64\n",
       "Notional Cost (£)      int64\n",
       "Date                  object\n",
       "cloud_cover          float64\n",
       "sunshine             float64\n",
       "global_radiation     float64\n",
       "max_temp             float64\n",
       "mean_temp            float64\n",
       "min_temp             float64\n",
       "precipitation        float64\n",
       "pressure             float64\n",
       "snow_depth           float64\n",
       "CostCat                int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset, print types\n",
    "df = pd.read_csv('preprocessing/data/london_clean.csv')\n",
    "df.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9537f34b",
   "metadata": {},
   "source": [
    "#### 3. Feature Selection and Dataset Split\n",
    "\n",
    "First, the entire dataset is split into input and output features - X and y respectively.\n",
    "<br>We wish to predict feature in <i>y</i> based on features grouped in <i>X</i> used as input values.\n",
    "<br>\n",
    "<Br>\n",
    "Both groups of input and output features are split into two subsets for their respective use with the help of Scikit-Learn's <i>train_test_split</i> function:\n",
    "<li>67% of the dataset is used to train the decision tree model\n",
    "<li>33% of the dataset is used to test the performance of the decision tree model\n",
    "<br>\n",
    "<br>\n",
    "In <i>train_test_split</i> function, the <i>random_state</i> variable is specified to 42.\n",
    "<br>This specification allows <i>train_test_split</i> function to generate the identical training and testing subsets every time it is called.\n",
    "<br>This functionality allows all three prediction models to be trained on the same dataset, allowing better comparison between thier performance in the later step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2705cd45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         DateOfCall  PropertyType  NumPumpsAttending  PumpHoursRoundUp  \\\n",
      "706975            5            12                  1                 1   \n",
      "450954            9             6                  2                 1   \n",
      "525760            6            12                  2                 1   \n",
      "20577             3            83                  2                 1   \n",
      "1069644          11            37                  1                 1   \n",
      "\n",
      "         mean_temp  \n",
      "706975        15.0  \n",
      "450954        13.3  \n",
      "525760        16.4  \n",
      "20577          7.6  \n",
      "1069644        8.3  \n",
      "         CostCat\n",
      "706975         0\n",
      "450954         0\n",
      "525760         0\n",
      "20577          0\n",
      "1069644        1\n"
     ]
    }
   ],
   "source": [
    "# do train and test split\n",
    "X = df[['DateOfCall', 'PropertyType', 'NumPumpsAttending', 'PumpHoursRoundUp', 'mean_temp']]\n",
    "y = df[['CostCat']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# print a small sample of train X and y\n",
    "print(X_train[0:5])\n",
    "print(y_train[0:5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "54fe14f0",
   "metadata": {},
   "source": [
    "#### 4. Model implementation and training\n",
    "Scikit-Learn's deicision tree classifier offers a range of parameters that can be tuned to control the behaviour of the decision tree model.\n",
    "<br>\n",
    "The following are the parameters we are interested in:\n",
    "<ol>\n",
    "<li><b><i>max_depth</i></b>: \n",
    "<br> - Sets the maximum depth of the decision tree\n",
    "<br> - A deeper tree can capture more complex relationships in the data, but can also lead to overfitting\n",
    "<br> - Default value = \"None\"\n",
    "<li><b><i>min_samples_split</i></b>: \n",
    "<br> - Sets the minimum number of samples required to split an internal node. \n",
    "<br> - A higher value can prevent the tree from splitting too early, leading to more robust models.\n",
    "<br> - Default value = 2\n",
    "<li><b><i>criterion</i></b>: \n",
    "<br> - Specifies the function used to measure the quality of a split. \n",
    "<br> - The two options are \"gini\" and \"entropy\", which correspond to the Gini impurity and information gain criteria, respectively.\n",
    "<br> - Default value = \"gini\"\n",
    "</ol>\n",
    "\n",
    "\n",
    "The first training and testing of the decision tree model is done with default parameters set by the Scikit-Learn library.\n",
    "<br>\n",
    "These hyper parameters will be specified in the following step, once the decision tree model provides an acceptable performance score with the current training and testing datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7abac23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and train decision tree\n",
    "clf = tree.DecisionTreeRegressor()\n",
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ec6554",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tree vizualization\n",
    "tree.plot_tree(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09e9cec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.85      0.81    231390\n",
      "           1       0.71      0.61      0.66    140418\n",
      "           2       1.00      1.00      1.00     34444\n",
      "           3       0.74      0.70      0.72      5421\n",
      "           4       0.57      0.60      0.58      4962\n",
      "           5       0.92      0.92      0.92      7949\n",
      "\n",
      "    accuracy                           0.78    424584\n",
      "   macro avg       0.79      0.78      0.78    424584\n",
      "weighted avg       0.77      0.78      0.77    424584\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "y_pred = clf.predict(X_test).round()\n",
    "print(\"Default Decision Tree Model Description\")\n",
    "print(\"Depth: \" + clf.get_depth())\n",
    "print(\"Number of Leaves: \" + clf.get_n_leaves())\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2fce405d",
   "metadata": {},
   "source": [
    "#### 5. Hyper-parameter Tuning\n",
    "\n",
    "Now that the decision tree model has proven to produce acceptable performance, we will try to specify its hyper parameters to determine the combination that maxmizes the model's performance score.\n",
    "\n",
    "Scikit-Learn offers an exhuastive search algorithm enabling us to easily determine the best hyper parameter combination called <b><i>GridSearchCV</i></b>\n",
    "The algorithm iterate over every combination possible of the input hyper parameter values and select the best one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597eeed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_params = {'criterion':['gini','entropy'],'max_depth':[3,5],'min_samples_split':[10,50,100]}\n",
    "dtc_top = GridSearchCV(DecisionTreeClassifier(), tree_params, cv=5)\n",
    "# Training the model for emotion classification\n",
    "model2_e_top = dtc_top.fit(vector_training_post, emotion_train)\n",
    "# Predict emotion class of test data\n",
    "predict_emotion5 = model2_e_top.predict(vector_test_post)\n",
    "print(\"Best hyperparameters for emotion classification: \", dtc_top.best_params_)\n",
    "\n",
    "# Training the model for sentiment classification\n",
    "model2_s_top = dtc_top.fit(vector_training_post, sentiment_train)\n",
    "# Predict sentiment class of new email\n",
    "predict_sentiment5 = model2_s_top.predict(vector_test_post)\n",
    "print(\"Best hyperparameters for sentiment classification: \", dtc_top.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
