{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# To change scientific numbers to float\n",
    "np.set_printoptions(formatter={'float_kind':'{:f}'.format})\n",
    "\n",
    "# Increases the size of sns plots\n",
    "sns.set(rc={'figure.figsize':(8,6)})\n",
    "\n",
    "# Datetime lib\n",
    "from pandas import to_datetime\n",
    "import itertools\n",
    "import warnings\n",
    "import datetime\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, r2_score, classification_report\n",
    "\n",
    "#for hyper parameter tunning\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/london_clean_weather.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateOfCall</th>\n",
       "      <th>CalYear</th>\n",
       "      <th>HourOfCall</th>\n",
       "      <th>IncidentGroup</th>\n",
       "      <th>PropertyCategory</th>\n",
       "      <th>PropertyType</th>\n",
       "      <th>NumPumpsAttending</th>\n",
       "      <th>PumpHoursRoundUp</th>\n",
       "      <th>Notional Cost (£)</th>\n",
       "      <th>Date</th>\n",
       "      <th>CostCat</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>sunshine</th>\n",
       "      <th>global_radiation</th>\n",
       "      <th>max_temp</th>\n",
       "      <th>mean_temp</th>\n",
       "      <th>min_temp</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>pressure</th>\n",
       "      <th>snow_depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>255</td>\n",
       "      <td>01/01/2009</td>\n",
       "      <td>3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103010.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>255</td>\n",
       "      <td>01/01/2009</td>\n",
       "      <td>3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103010.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>255</td>\n",
       "      <td>01/01/2009</td>\n",
       "      <td>3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103010.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>255</td>\n",
       "      <td>01/01/2009</td>\n",
       "      <td>3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103010.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>255</td>\n",
       "      <td>01/01/2009</td>\n",
       "      <td>3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103010.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>326</td>\n",
       "      <td>04/11/2016</td>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>17.4</td>\n",
       "      <td>11.6</td>\n",
       "      <td>8.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100580.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>326</td>\n",
       "      <td>04/11/2016</td>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>17.4</td>\n",
       "      <td>11.6</td>\n",
       "      <td>8.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100580.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>326</td>\n",
       "      <td>04/11/2016</td>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>17.4</td>\n",
       "      <td>11.6</td>\n",
       "      <td>8.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100580.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>652</td>\n",
       "      <td>04/11/2016</td>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>17.4</td>\n",
       "      <td>11.6</td>\n",
       "      <td>8.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100580.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>326</td>\n",
       "      <td>04/11/2016</td>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>17.4</td>\n",
       "      <td>11.6</td>\n",
       "      <td>8.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100580.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>522 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     DateOfCall  CalYear  HourOfCall  IncidentGroup  PropertyCategory  \\\n",
       "0             1     2009           0              0                 0   \n",
       "1             1     2009           0              1                 1   \n",
       "2             1     2009           0              1                 1   \n",
       "3             1     2009           0              1                 1   \n",
       "4             1     2009           0              2                 2   \n",
       "..          ...      ...         ...            ...               ...   \n",
       "517           4     2016          10              2                 5   \n",
       "518           4     2016          10              2                 2   \n",
       "519           4     2016          10              2                 5   \n",
       "520           4     2016          10              1                 5   \n",
       "521           4     2016          10              0                 2   \n",
       "\n",
       "     PropertyType  NumPumpsAttending  PumpHoursRoundUp  Notional Cost (£)  \\\n",
       "0               0                  2                 1                255   \n",
       "1               1                  1                 1                255   \n",
       "2               2                  1                 1                255   \n",
       "3               3                  2                 1                255   \n",
       "4               4                  2                 1                255   \n",
       "..            ...                ...               ...                ...   \n",
       "517            33                  1                 1                326   \n",
       "518            22                  2                 1                326   \n",
       "519            68                  1                 1                326   \n",
       "520            70                  2                 2                652   \n",
       "521            12                  1                 1                326   \n",
       "\n",
       "           Date  CostCat  cloud_cover  sunshine  global_radiation  max_temp  \\\n",
       "0    01/01/2009        3          8.0       0.0              13.0       3.5   \n",
       "1    01/01/2009        3          8.0       0.0              13.0       3.5   \n",
       "2    01/01/2009        3          8.0       0.0              13.0       3.5   \n",
       "3    01/01/2009        3          8.0       0.0              13.0       3.5   \n",
       "4    01/01/2009        3          8.0       0.0              13.0       3.5   \n",
       "..          ...      ...          ...       ...               ...       ...   \n",
       "517  04/11/2016        4          7.0       1.0              92.0      17.4   \n",
       "518  04/11/2016        4          7.0       1.0              92.0      17.4   \n",
       "519  04/11/2016        4          7.0       1.0              92.0      17.4   \n",
       "520  04/11/2016        7          7.0       1.0              92.0      17.4   \n",
       "521  04/11/2016        4          7.0       1.0              92.0      17.4   \n",
       "\n",
       "     mean_temp  min_temp  precipitation  pressure  snow_depth  \n",
       "0          1.5      -0.5            0.0  103010.0         0.0  \n",
       "1          1.5      -0.5            0.0  103010.0         0.0  \n",
       "2          1.5      -0.5            0.0  103010.0         0.0  \n",
       "3          1.5      -0.5            0.0  103010.0         0.0  \n",
       "4          1.5      -0.5            0.0  103010.0         0.0  \n",
       "..         ...       ...            ...       ...         ...  \n",
       "517       11.6       8.8            3.0  100580.0         0.0  \n",
       "518       11.6       8.8            3.0  100580.0         0.0  \n",
       "519       11.6       8.8            3.0  100580.0         0.0  \n",
       "520       11.6       8.8            3.0  100580.0         0.0  \n",
       "521       11.6       8.8            3.0  100580.0         0.0  \n",
       "\n",
       "[522 rows x 20 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DateOfCall            0\n",
       "CalYear               0\n",
       "HourOfCall            0\n",
       "IncidentGroup         0\n",
       "PropertyCategory      0\n",
       "PropertyType          0\n",
       "NumPumpsAttending     0\n",
       "PumpHoursRoundUp      0\n",
       "Notional Cost (£)     0\n",
       "Date                  0\n",
       "CostCat               0\n",
       "cloud_cover           0\n",
       "sunshine              0\n",
       "global_radiation      0\n",
       "max_temp              0\n",
       "mean_temp             0\n",
       "min_temp              0\n",
       "precipitation         0\n",
       "pressure              0\n",
       "snow_depth           62\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DateOfCall', 'CalYear', 'HourOfCall', 'IncidentGroup',\n",
       "       'PropertyCategory', 'PropertyType', 'NumPumpsAttending',\n",
       "       'PumpHoursRoundUp', 'Notional Cost (£)', 'Date', 'CostCat',\n",
       "       'cloud_cover', 'sunshine', 'global_radiation', 'max_temp', 'mean_temp',\n",
       "       'min_temp', 'precipitation', 'pressure', 'snow_depth'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc[:, ['DateOfCall', 'PropertyType', 'NumPumpsAttending',\n",
    "       'PumpHoursRoundUp', 'Notional Cost (£)', 'mean_temp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# g = sns.pairplot(data, hue = 'EstimatedPropertyLoss', diag_kws={'bw': 0.2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#identify all categorical variables\n",
    "cat_columns = data.select_dtypes(['object']).columns\n",
    "cat_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (522, 5)\n",
      "y shape: (522,)\n"
     ]
    }
   ],
   "source": [
    "X = data.drop(['Notional Cost (£)'], axis=1).values# Input features (attributes)\n",
    "y = data['Notional Cost (£)'].values # Target vector\n",
    "print('X shape: {}'.format(np.shape(X)))\n",
    "print('y shape: {}'.format(np.shape(y)))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.7, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix function\n",
    "\n",
    "def plot_confusion_matrix(cm, classes=None, title='Confusion matrix'):\n",
    "    \"\"\"Plots a confusion matrix.\"\"\"\n",
    "    if classes is not None:\n",
    "        sns.heatmap(cm, xticklabels=classes, yticklabels=classes, vmin=0., vmax=1., annot=True, annot_kws={'size':50})\n",
    "    else:\n",
    "        sns.heatmap(cm, vmin=0., vmax=1.)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy is:  1.0\n",
      "Testing Accuracy is:  0.9808917197452229\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         255       1.00      1.00      1.00        22\n",
      "         260       1.00      1.00      1.00        75\n",
      "         290       1.00      1.00      1.00         9\n",
      "         326       1.00      1.00      1.00        28\n",
      "         510       1.00      1.00      1.00         2\n",
      "         520       0.80      1.00      0.89         8\n",
      "         580       1.00      1.00      1.00         2\n",
      "         652       1.00      1.00      1.00         3\n",
      "         765       1.00      1.00      1.00         2\n",
      "         780       0.50      1.00      0.67         1\n",
      "         978       1.00      1.00      1.00         1\n",
      "        1300       0.00      0.00      0.00         1\n",
      "        1530       1.00      1.00      1.00         1\n",
      "        1560       0.00      0.00      0.00         1\n",
      "       81380       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.98       157\n",
      "   macro avg       0.75      0.80      0.77       157\n",
      "weighted avg       0.97      0.98      0.97       157\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, criterion='entropy')\n",
    "rf.fit(X_train, y_train)\n",
    "prediction_test = rf.predict(X=X_test)\n",
    "\n",
    "# source: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "\n",
    "# Accuracy on Test\n",
    "print(\"Training Accuracy is: \", rf.score(X_train, y_train))\n",
    "# Accuracy on Train\n",
    "print(\"Testing Accuracy is: \", rf.score(X_test, y_test))\n",
    "\n",
    "print(classification_report(y_test, prediction_test))\n",
    "\n",
    "# Confusion Matrix\n",
    "# cm = confusion_matrix(y_test, prediction_test)\n",
    "# cm_norm = cm/cm.sum(axis=1)[:, np.newaxis]\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cm_norm, classes=rf.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Tunning Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy on test set with max features = 1 and max_depth = None: 0.968\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         255       1.00      1.00      1.00        22\n",
      "         260       1.00      1.00      1.00        75\n",
      "         290       1.00      1.00      1.00         9\n",
      "         326       1.00      1.00      1.00        28\n",
      "         510       0.50      1.00      0.67         2\n",
      "         520       0.80      1.00      0.89         8\n",
      "         580       1.00      1.00      1.00         2\n",
      "         652       1.00      1.00      1.00         3\n",
      "         765       1.00      0.50      0.67         2\n",
      "         780       1.00      1.00      1.00         1\n",
      "         978       1.00      1.00      1.00         1\n",
      "        1300       0.00      0.00      0.00         1\n",
      "        1530       0.00      0.00      0.00         1\n",
      "        1560       0.00      0.00      0.00         1\n",
      "        2805       0.00      0.00      0.00         0\n",
      "       81380       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.97       157\n",
      "   macro avg       0.64      0.66      0.64       157\n",
      "weighted avg       0.96      0.97      0.96       157\n",
      "\n",
      "Classification accuracy on test set with max features = 1 and max_depth = 2: 0.484\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         255       0.17      0.05      0.07        22\n",
      "         260       0.50      1.00      0.67        75\n",
      "         290       0.00      0.00      0.00         9\n",
      "         326       0.00      0.00      0.00        28\n",
      "         510       0.00      0.00      0.00         2\n",
      "         520       0.00      0.00      0.00         8\n",
      "         580       0.00      0.00      0.00         2\n",
      "         652       0.00      0.00      0.00         3\n",
      "         765       0.00      0.00      0.00         2\n",
      "         780       0.00      0.00      0.00         1\n",
      "         978       0.00      0.00      0.00         1\n",
      "        1300       0.00      0.00      0.00         1\n",
      "        1530       0.00      0.00      0.00         1\n",
      "        1560       0.00      0.00      0.00         1\n",
      "       81380       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.48       157\n",
      "   macro avg       0.04      0.07      0.05       157\n",
      "weighted avg       0.26      0.48      0.33       157\n",
      "\n",
      "Classification accuracy on test set with max features = 1 and max_depth = 3: 0.803\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         255       1.00      1.00      1.00        22\n",
      "         260       0.77      1.00      0.87        75\n",
      "         290       0.82      1.00      0.90         9\n",
      "         326       0.82      0.64      0.72        28\n",
      "         510       0.40      1.00      0.57         2\n",
      "         520       0.00      0.00      0.00         8\n",
      "         580       0.00      0.00      0.00         2\n",
      "         652       0.00      0.00      0.00         3\n",
      "         765       0.00      0.00      0.00         2\n",
      "         780       0.00      0.00      0.00         1\n",
      "         978       0.00      0.00      0.00         1\n",
      "        1300       0.00      0.00      0.00         1\n",
      "        1530       0.00      0.00      0.00         1\n",
      "        1560       0.00      0.00      0.00         1\n",
      "       81380       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.80       157\n",
      "   macro avg       0.25      0.31      0.27       157\n",
      "weighted avg       0.71      0.80      0.74       157\n",
      "\n",
      "Classification accuracy on test set with max features = 1 and max_depth = 4: 0.904\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         255       1.00      1.00      1.00        22\n",
      "         260       0.87      1.00      0.93        75\n",
      "         290       1.00      1.00      1.00         9\n",
      "         326       0.97      1.00      0.98        28\n",
      "         510       0.40      1.00      0.57         2\n",
      "         520       1.00      0.12      0.22         8\n",
      "         580       1.00      1.00      1.00         2\n",
      "         652       1.00      1.00      1.00         3\n",
      "         765       0.00      0.00      0.00         2\n",
      "         780       0.00      0.00      0.00         1\n",
      "         978       0.00      0.00      0.00         1\n",
      "        1300       0.00      0.00      0.00         1\n",
      "        1530       0.00      0.00      0.00         1\n",
      "        1560       0.00      0.00      0.00         1\n",
      "       81380       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.90       157\n",
      "   macro avg       0.48      0.47      0.45       157\n",
      "weighted avg       0.87      0.90      0.87       157\n",
      "\n",
      "Classification accuracy on test set with max features = 1 and max_depth = 5: 0.955\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         255       1.00      1.00      1.00        22\n",
      "         260       0.97      1.00      0.99        75\n",
      "         290       1.00      1.00      1.00         9\n",
      "         326       1.00      1.00      1.00        28\n",
      "         510       0.40      1.00      0.57         2\n",
      "         520       0.78      0.88      0.82         8\n",
      "         580       1.00      1.00      1.00         2\n",
      "         652       1.00      1.00      1.00         3\n",
      "         765       0.00      0.00      0.00         2\n",
      "         780       1.00      1.00      1.00         1\n",
      "         978       1.00      1.00      1.00         1\n",
      "        1300       0.00      0.00      0.00         1\n",
      "        1530       0.00      0.00      0.00         1\n",
      "        1560       0.00      0.00      0.00         1\n",
      "       81380       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.96       157\n",
      "   macro avg       0.61      0.66      0.63       157\n",
      "weighted avg       0.93      0.96      0.94       157\n",
      "\n",
      "Classification accuracy on test set with max features = sqrt and max_depth = None: 0.981\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         255       1.00      1.00      1.00        22\n",
      "         260       1.00      1.00      1.00        75\n",
      "         290       1.00      1.00      1.00         9\n",
      "         326       1.00      1.00      1.00        28\n",
      "         510       1.00      1.00      1.00         2\n",
      "         520       0.80      1.00      0.89         8\n",
      "         580       1.00      1.00      1.00         2\n",
      "         652       1.00      1.00      1.00         3\n",
      "         765       1.00      1.00      1.00         2\n",
      "         780       1.00      1.00      1.00         1\n",
      "         978       1.00      1.00      1.00         1\n",
      "        1300       0.00      0.00      0.00         1\n",
      "        1530       1.00      1.00      1.00         1\n",
      "        1560       0.00      0.00      0.00         1\n",
      "        3640       0.00      0.00      0.00         0\n",
      "       81380       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.98       157\n",
      "   macro avg       0.74      0.75      0.74       157\n",
      "weighted avg       0.97      0.98      0.98       157\n",
      "\n",
      "Classification accuracy on test set with max features = sqrt and max_depth = 2: 0.854\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         255       0.81      1.00      0.90        22\n",
      "         260       0.86      1.00      0.93        75\n",
      "         290       0.82      1.00      0.90         9\n",
      "         326       0.88      1.00      0.93        28\n",
      "         510       0.00      0.00      0.00         2\n",
      "         520       0.00      0.00      0.00         8\n",
      "         580       0.00      0.00      0.00         2\n",
      "         652       0.00      0.00      0.00         3\n",
      "         765       0.00      0.00      0.00         2\n",
      "         780       0.00      0.00      0.00         1\n",
      "         978       0.00      0.00      0.00         1\n",
      "        1300       0.00      0.00      0.00         1\n",
      "        1530       0.00      0.00      0.00         1\n",
      "        1560       0.00      0.00      0.00         1\n",
      "       81380       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.85       157\n",
      "   macro avg       0.22      0.27      0.24       157\n",
      "weighted avg       0.73      0.85      0.79       157\n",
      "\n",
      "Classification accuracy on test set with max features = sqrt and max_depth = 3: 0.924\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         255       0.96      1.00      0.98        22\n",
      "         260       0.93      1.00      0.96        75\n",
      "         290       1.00      1.00      1.00         9\n",
      "         326       1.00      1.00      1.00        28\n",
      "         510       0.50      1.00      0.67         2\n",
      "         520       0.67      0.50      0.57         8\n",
      "         580       1.00      1.00      1.00         2\n",
      "         652       0.75      1.00      0.86         3\n",
      "         765       0.00      0.00      0.00         2\n",
      "         780       0.00      0.00      0.00         1\n",
      "         978       0.00      0.00      0.00         1\n",
      "        1300       0.00      0.00      0.00         1\n",
      "        1530       0.00      0.00      0.00         1\n",
      "        1560       0.00      0.00      0.00         1\n",
      "       81380       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.92       157\n",
      "   macro avg       0.45      0.50      0.47       157\n",
      "weighted avg       0.88      0.92      0.90       157\n",
      "\n",
      "Classification accuracy on test set with max features = sqrt and max_depth = 4: 0.962\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         255       1.00      1.00      1.00        22\n",
      "         260       1.00      1.00      1.00        75\n",
      "         290       1.00      1.00      1.00         9\n",
      "         326       1.00      1.00      1.00        28\n",
      "         510       0.40      1.00      0.57         2\n",
      "         520       0.80      1.00      0.89         8\n",
      "         580       1.00      1.00      1.00         2\n",
      "         652       1.00      1.00      1.00         3\n",
      "         765       0.00      0.00      0.00         2\n",
      "         780       0.50      1.00      0.67         1\n",
      "         978       1.00      1.00      1.00         1\n",
      "        1300       0.00      0.00      0.00         1\n",
      "        1530       0.00      0.00      0.00         1\n",
      "        1560       0.00      0.00      0.00         1\n",
      "       81380       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.96       157\n",
      "   macro avg       0.58      0.67      0.61       157\n",
      "weighted avg       0.94      0.96      0.95       157\n",
      "\n",
      "Classification accuracy on test set with max features = sqrt and max_depth = 5: 0.975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         255       1.00      1.00      1.00        22\n",
      "         260       1.00      1.00      1.00        75\n",
      "         290       1.00      1.00      1.00         9\n",
      "         326       1.00      1.00      1.00        28\n",
      "         510       0.67      1.00      0.80         2\n",
      "         520       0.80      1.00      0.89         8\n",
      "         580       1.00      1.00      1.00         2\n",
      "         652       1.00      1.00      1.00         3\n",
      "         765       1.00      1.00      1.00         2\n",
      "         780       0.50      1.00      0.67         1\n",
      "         978       1.00      1.00      1.00         1\n",
      "        1300       0.00      0.00      0.00         1\n",
      "        1530       0.00      0.00      0.00         1\n",
      "        1560       0.00      0.00      0.00         1\n",
      "       81380       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.97       157\n",
      "   macro avg       0.66      0.73      0.69       157\n",
      "weighted avg       0.96      0.97      0.96       157\n",
      "\n",
      "Classification accuracy on test set with max features = log2 and max_depth = None: 0.981\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         255       1.00      1.00      1.00        22\n",
      "         260       1.00      1.00      1.00        75\n",
      "         290       1.00      1.00      1.00         9\n",
      "         326       1.00      1.00      1.00        28\n",
      "         510       1.00      1.00      1.00         2\n",
      "         520       0.80      1.00      0.89         8\n",
      "         580       1.00      1.00      1.00         2\n",
      "         652       1.00      1.00      1.00         3\n",
      "         765       1.00      1.00      1.00         2\n",
      "         780       1.00      1.00      1.00         1\n",
      "         978       1.00      1.00      1.00         1\n",
      "        1300       0.00      0.00      0.00         1\n",
      "        1530       1.00      1.00      1.00         1\n",
      "        1560       0.00      0.00      0.00         1\n",
      "        3640       0.00      0.00      0.00         0\n",
      "       81380       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.98       157\n",
      "   macro avg       0.74      0.75      0.74       157\n",
      "weighted avg       0.97      0.98      0.98       157\n",
      "\n",
      "Classification accuracy on test set with max features = log2 and max_depth = 2: 0.854\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         255       0.81      1.00      0.90        22\n",
      "         260       0.86      1.00      0.93        75\n",
      "         290       0.82      1.00      0.90         9\n",
      "         326       0.88      1.00      0.93        28\n",
      "         510       0.00      0.00      0.00         2\n",
      "         520       0.00      0.00      0.00         8\n",
      "         580       0.00      0.00      0.00         2\n",
      "         652       0.00      0.00      0.00         3\n",
      "         765       0.00      0.00      0.00         2\n",
      "         780       0.00      0.00      0.00         1\n",
      "         978       0.00      0.00      0.00         1\n",
      "        1300       0.00      0.00      0.00         1\n",
      "        1530       0.00      0.00      0.00         1\n",
      "        1560       0.00      0.00      0.00         1\n",
      "       81380       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.85       157\n",
      "   macro avg       0.22      0.27      0.24       157\n",
      "weighted avg       0.73      0.85      0.79       157\n",
      "\n",
      "Classification accuracy on test set with max features = log2 and max_depth = 3: 0.924\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         255       0.96      1.00      0.98        22\n",
      "         260       0.93      1.00      0.96        75\n",
      "         290       1.00      1.00      1.00         9\n",
      "         326       1.00      1.00      1.00        28\n",
      "         510       0.50      1.00      0.67         2\n",
      "         520       0.67      0.50      0.57         8\n",
      "         580       1.00      1.00      1.00         2\n",
      "         652       0.75      1.00      0.86         3\n",
      "         765       0.00      0.00      0.00         2\n",
      "         780       0.00      0.00      0.00         1\n",
      "         978       0.00      0.00      0.00         1\n",
      "        1300       0.00      0.00      0.00         1\n",
      "        1530       0.00      0.00      0.00         1\n",
      "        1560       0.00      0.00      0.00         1\n",
      "       81380       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.92       157\n",
      "   macro avg       0.45      0.50      0.47       157\n",
      "weighted avg       0.88      0.92      0.90       157\n",
      "\n",
      "Classification accuracy on test set with max features = log2 and max_depth = 4: 0.962\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         255       1.00      1.00      1.00        22\n",
      "         260       1.00      1.00      1.00        75\n",
      "         290       1.00      1.00      1.00         9\n",
      "         326       1.00      1.00      1.00        28\n",
      "         510       0.40      1.00      0.57         2\n",
      "         520       0.80      1.00      0.89         8\n",
      "         580       1.00      1.00      1.00         2\n",
      "         652       1.00      1.00      1.00         3\n",
      "         765       0.00      0.00      0.00         2\n",
      "         780       0.50      1.00      0.67         1\n",
      "         978       1.00      1.00      1.00         1\n",
      "        1300       0.00      0.00      0.00         1\n",
      "        1530       0.00      0.00      0.00         1\n",
      "        1560       0.00      0.00      0.00         1\n",
      "       81380       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.96       157\n",
      "   macro avg       0.58      0.67      0.61       157\n",
      "weighted avg       0.94      0.96      0.95       157\n",
      "\n",
      "Classification accuracy on test set with max features = log2 and max_depth = 5: 0.975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         255       1.00      1.00      1.00        22\n",
      "         260       1.00      1.00      1.00        75\n",
      "         290       1.00      1.00      1.00         9\n",
      "         326       1.00      1.00      1.00        28\n",
      "         510       0.67      1.00      0.80         2\n",
      "         520       0.80      1.00      0.89         8\n",
      "         580       1.00      1.00      1.00         2\n",
      "         652       1.00      1.00      1.00         3\n",
      "         765       1.00      1.00      1.00         2\n",
      "         780       0.50      1.00      0.67         1\n",
      "         978       1.00      1.00      1.00         1\n",
      "        1300       0.00      0.00      0.00         1\n",
      "        1530       0.00      0.00      0.00         1\n",
      "        1560       0.00      0.00      0.00         1\n",
      "       81380       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.97       157\n",
      "   macro avg       0.66      0.73      0.69       157\n",
      "weighted avg       0.96      0.97      0.96       157\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_estimators = 100\n",
    "max_features = [1, 'sqrt', 'log2']\n",
    "max_depths = [None, 2, 3, 4, 5]\n",
    "for f, d in product(max_features, max_depths): # with product we can iterate through all possible combinations\n",
    "    rf = RandomForestClassifier(n_estimators=n_estimators,\n",
    "                                criterion='entropy',\n",
    "                                max_features=f,\n",
    "                                max_depth=d,\n",
    "                                n_jobs=2,\n",
    "                                random_state=1337)\n",
    "    rf.fit(X_train, y_train)\n",
    "    prediction_test = rf.predict(X=X_test)\n",
    "    print('Classification accuracy on test set with max features = {} and max_depth = {}: {:.3f}'.format(f, d, accuracy_score(y_test,prediction_test)))\n",
    "    print(classification_report(y_test, prediction_test))\n",
    "    # cm = confusion_matrix(y_test, prediction_test)\n",
    "    # cm_norm = cm/cm.sum(axis=1)[:, np.newaxis]\n",
    "    # # plt.figure()\n",
    "    # plot_confusion_matrix(cm_norm, classes=rf.classes_,\n",
    "    # title='Confusion matrix accuracy on test set with max features = {} and max_depth = {}: {:.3f}'.format(f, d, accuracy_score(y_test,prediction_test)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters for random forest classification:  {'criterion': 'entropy', 'max_depth': 6, 'max_features': None, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "tree_params = {'n_estimators':[50, 100, 150, 200],'criterion':['gini','entropy', 'log_loss'],'max_depth':[2, 3, 4, 5, 6, 7, 8, 9, 10], 'max_features':['sqrt', 'log2', None]}\n",
    "rf_top = GridSearchCV( RandomForestClassifier(), tree_params, cv=5)\n",
    "\n",
    "# Training the model for emotion classification\n",
    "rf_top2 = rf_top.fit(X_train, y_train)\n",
    "\n",
    "# Display the best hyperparameters\n",
    "print(\"Best hyperparameters for random forest classification: \", rf_top.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy on test set with max features = None and max_depth = 6: 0.987\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         255       1.00      1.00      1.00        22\n",
      "         260       1.00      1.00      1.00        75\n",
      "         290       1.00      1.00      1.00         9\n",
      "         326       1.00      1.00      1.00        28\n",
      "         510       1.00      1.00      1.00         2\n",
      "         520       1.00      1.00      1.00         8\n",
      "         580       1.00      1.00      1.00         2\n",
      "         652       1.00      1.00      1.00         3\n",
      "         765       1.00      1.00      1.00         2\n",
      "         780       1.00      1.00      1.00         1\n",
      "         978       1.00      1.00      1.00         1\n",
      "        1300       0.50      1.00      0.67         1\n",
      "        1530       1.00      1.00      1.00         1\n",
      "        1560       0.00      0.00      0.00         1\n",
      "        3640       0.00      0.00      0.00         0\n",
      "       81380       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.99       157\n",
      "   macro avg       0.78      0.81      0.79       157\n",
      "weighted avg       0.98      0.99      0.99       157\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict emotion class of test data\n",
    "rf_top_predict = rf_top2.predict(X=X_test)\n",
    "print('Classification accuracy on test set with max features = {} and max_depth = {}: {:.3f}'.format(None, 6, accuracy_score(y_test,rf_top_predict)))\n",
    "print(classification_report(y_test, rf_top_predict))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
